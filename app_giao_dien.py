import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from io import StringIO

# =============================================================================
# 1ï¸âƒ£ Táº¢I HÃ€M Xá»¬ LÃ PIPELINE
# =============================================================================
try:
    from pipeline_ABSA import load_all_models, run_full_pipeline
except ImportError as e:
    st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file 'pipeline_ABSA.py'. {e}")
    st.stop()

# =============================================================================
# 2ï¸âƒ£ GIAO DIá»†N CHÃNH (KIá»‚U DASHBOARD)
# =============================================================================
st.set_page_config(page_title="ABSA Sentiment Dashboard", layout="wide")
st.title("ðŸ§  ABSA Sentiment Analysis â€” Dashboard")
st.caption("PhÃ¢n tÃ­ch cáº£m xÃºc & khÃ­a cáº¡nh (Aspect-Based Sentiment Analysis)")

# =============================================================================
# 3ï¸âƒ£ LOAD MODELS (CACHE)
# =============================================================================
@st.cache_resource
def get_models():
    return load_all_models()

models = get_models()
if not all(models.values()):
    st.error("Má»™t hoáº·c nhiá»u mÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c táº£i. Kiá»ƒm tra file pipeline_ABSA.py.")
    st.stop()

# =============================================================================
# 4ï¸âƒ£ HÃ€M HIá»‚N THá»Š DASHBOARD
# =============================================================================
def render_dashboard(results_df: pd.DataFrame):
    # --- Chuáº©n hÃ³a cá»™t ---
    for col in ["category", "Category"]:
        if col in results_df.columns:
            results_df["Category"] = results_df[col]
    for col in ["polarity", "Polarity"]:
        if col in results_df.columns:
            results_df["Polarity"] = results_df[col]

    st.markdown("### ðŸŽ¯ Tá»•ng quan cáº£m xÃºc")
    pos = sum(results_df["Polarity"].str.lower() == "positive")
    neg = sum(results_df["Polarity"].str.lower() == "negative")
    neu = sum(results_df["Polarity"].str.lower() == "neutral")
    total = pos + neg + neu
    score = ((pos - neg) / max(total, 1) + 1) * 50

    # --- NhÃ³m 3 biá»ƒu Ä‘á»“ cáº¡nh nhau ---
    st.markdown("### ðŸ“Š Tá»•ng quan thá»‘ng kÃª cáº£m xÃºc")

    # Táº¡o 3 cá»™t song song
    col1, col2, col3 = st.columns(3)

    # --- 1ï¸âƒ£ Sentiment Score ---
    with col1:
        st.markdown("#### ðŸŽ¯ Sentiment Score")
        fig1, ax1 = plt.subplots(figsize=(2.5, 2))  # giáº£m kÃ­ch thÆ°á»›c
        color = "green" if score > 60 else "red" if score < 40 else "gray"
        ax1.barh(["Score"], [score], color=color)
        ax1.set_xlim(0, 100)
        ax1.set_xlabel("0â€“100 sentiment score")
        st.pyplot(fig1)

    # --- 2ï¸âƒ£ Category ---
    with col2:
        st.markdown("#### ðŸ“‚ Category")
        if "Category" in results_df.columns:
            cat_counts = results_df["Category"].value_counts()
            fig2, ax2 = plt.subplots(figsize=(2.5, 2))
            ax2.bar(cat_counts.index, cat_counts.values, color="skyblue")
            ax2.set_xticklabels(cat_counts.index, rotation=45, ha="right", fontsize=8)
            ax2.set_ylabel("")
            st.pyplot(fig2)
        else:
            st.info("KhÃ´ng cÃ³ dá»¯ liá»‡u Category")

    # --- 3ï¸âƒ£ Polarity ---
    with col3:
        st.markdown("#### ðŸŽ­ Polarity")
        if "Polarity" in results_df.columns:
            pol_counts = results_df["Polarity"].value_counts()
            colors = ["green" if i.lower() == "positive" else "gray" if i.lower() == "neutral" else "red"
                    for i in pol_counts.index]
            fig3, ax3 = plt.subplots(figsize=(2.5, 2))
            ax3.bar(pol_counts.index, pol_counts.values, color=colors)
            ax3.set_xticklabels(pol_counts.index, rotation=0, ha="center", fontsize=8)
            ax3.set_ylabel("")
            st.pyplot(fig3)
        else:
            st.info("KhÃ´ng cÃ³ dá»¯ liá»‡u Polarity")

    # --- WordCloud Term ---
    st.markdown("### â˜ï¸ Word Cloud â€” Term ná»•i báº­t")
    if "term" in results_df.columns or "Term" in results_df.columns:
        text_terms = " ".join(results_df.get("term", results_df.get("Term", pd.Series())).dropna().astype(str))
        if text_terms.strip():
            wc = WordCloud(width=800, height=300, background_color="white", colormap="viridis").generate(text_terms)
            plt.figure(figsize=(8, 4))
            plt.imshow(wc, interpolation="bilinear")
            plt.axis("off")
            st.pyplot(plt)
        else:
            st.info("KhÃ´ng cÃ³ Term Ä‘á»ƒ hiá»ƒn thá»‹ WordCloud.")
    else:
        st.info("KhÃ´ng cÃ³ cá»™t Term trong dá»¯ liá»‡u.")

    # --- WordCloud Opinion ---
    st.markdown("### ðŸ’­ Word Cloud â€” Opinion ná»•i báº­t")
    if "opinion" in results_df.columns or "Opinion" in results_df.columns:
        text_ops = " ".join(results_df.get("opinion", results_df.get("Opinion", pd.Series())).dropna().astype(str))
        if text_ops.strip():
            wc = WordCloud(width=800, height=300, background_color="white", colormap="cool").generate(text_ops)
            plt.figure(figsize=(8, 4))
            plt.imshow(wc, interpolation="bilinear")
            plt.axis("off")
            st.pyplot(plt)
        else:
            st.info("KhÃ´ng cÃ³ Opinion Ä‘á»ƒ hiá»ƒn thá»‹ WordCloud.")
    else:
        st.info("KhÃ´ng cÃ³ cá»™t Opinion trong dá»¯ liá»‡u.")

    # --- Báº£ng dá»¯ liá»‡u chi tiáº¿t ---
    st.markdown("### ðŸ“‹ Báº£ng chi tiáº¿t káº¿t quáº£")
    st.dataframe(results_df, use_container_width=True)

    # --- Xuáº¥t file CSV ---
    csv = results_df.to_csv(index=False).encode("utf-8")
    st.download_button("ðŸ’¾ Táº£i CSV káº¿t quáº£", csv, "absa_results.csv", "text/csv")

# =============================================================================
# 5ï¸âƒ£ TAB: SINGLE & BATCH
# =============================================================================
tab1, tab2 = st.tabs(["ðŸ“ PhÃ¢n tÃ­ch 1 review", "ðŸ“¤ PhÃ¢n tÃ­ch file hÃ ng loáº¡t"])

# --- TAB 1 ---
with tab1:
    st.subheader("âœï¸ Nháº­p cÃ¢u review")
    default_sentence = "The food was great and the staff was friendly, but the room was small and dirty."
    text_input = st.text_area("Nháº­p ná»™i dung:", default_sentence, height=150)
    col1, col2 = st.columns([1, 1])
    analyze = col1.button("ðŸ” PhÃ¢n tÃ­ch", use_container_width=True, key="single_btn")
    clear = col2.button("ðŸ§¹ XÃ³a", use_container_width=True, key="clear_btn")
    if clear:
        st.experimental_rerun()

    if analyze and text_input.strip():
        try:
            st.info("â³ Äang cháº¡y pipeline...")
            df = run_full_pipeline(text_input, models)
            if df.empty:
                st.warning("KhÃ´ng cÃ³ káº¿t quáº£ tá»« pipeline.")
            else:
                st.success("âœ… PhÃ¢n tÃ­ch hoÃ n táº¥t!")
                render_dashboard(df)
        except Exception as e:
            st.error(f"Lá»—i: {e}")
            st.exception(e)

# --- TAB 2 ---
with tab2:
    st.subheader("ðŸ“‚ Táº£i file .txt (má»—i dÃ²ng lÃ  1 review)")
    uploaded_file = st.file_uploader("Chá»n file", type=["txt"])
    if st.button("ðŸš€ Cháº¡y phÃ¢n tÃ­ch hÃ ng loáº¡t", key="batch_btn"):
        if uploaded_file is None:
            st.warning("Vui lÃ²ng táº£i lÃªn file.")
        else:
            try:
                stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                reviews = [line.strip() for line in stringio.readlines() if line.strip()]
            except Exception as e:
                st.error(f"Lá»—i Ä‘á»c file: {e}")
                st.stop()

            if not reviews:
                st.warning("File trá»‘ng hoáº·c khÃ´ng há»£p lá»‡.")
            else:
                all_results = []
                st.info(f"Äang xá»­ lÃ½ {len(reviews)} dÃ²ng...")
                progress = st.progress(0)
                for i, review in enumerate(reviews):
                    try:
                        df = run_full_pipeline(review, models)
                        if not df.empty:
                            df["review_line"] = i + 1
                            df["review_text"] = review
                            all_results.append(df)
                    except Exception as e:
                        st.error(f"Lá»—i dÃ²ng {i+1}: {e}")
                    progress.progress((i + 1) / len(reviews))
                progress.empty()

                if not all_results:
                    st.warning("KhÃ´ng tÃ¬m tháº¥y khÃ­a cáº¡nh nÃ o.")
                else:
                    final_df = pd.concat(all_results, ignore_index=True)
                    st.success(f"âœ… HoÃ n táº¥t! {len(final_df)} khÃ­a cáº¡nh Ä‘Æ°á»£c tÃ¬m tháº¥y.")
                    render_dashboard(final_df)

st.markdown("---")
st.caption("âœ¨ Dashboard ABSA hoÃ n thiá»‡n: Category + Polarity chart + WordCloud Term/Opinion.")